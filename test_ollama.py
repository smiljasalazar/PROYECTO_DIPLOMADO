"""
Test Ollama + ChromaDB RAG
"""
import requests

print("="*50)
print("ğŸ§ª TEST: Ollama + ChromaDB RAG")
print("="*50)

# 1. Test Ollama connection
print("\n1ï¸âƒ£ Probando conexiÃ³n a Ollama...")
try:
    r = requests.get("http://localhost:11434/api/tags", timeout=5)
    if r.status_code == 200:
        models = [m["name"] for m in r.json().get("models", [])]
        print(f"   âœ… Ollama conectado")
        print(f"   ğŸ“¦ Modelos disponibles: {models}")
    else:
        print(f"   âŒ Error: {r.status_code}")
except requests.exceptions.ConnectionError:
    print("   âŒ Ollama no estÃ¡ corriendo!")
    print("   ğŸ‘‰ Ejecuta: ollama serve")
    exit(1)

# 2. Test generation
print("\n2ï¸âƒ£ Probando generaciÃ³n...")
response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "llama2",  # Cambia a tu modelo
        "prompt": "Responde en espaÃ±ol: Â¿QuÃ© es la hipertensiÃ³n?",
        "stream": False,
        "options": {"num_predict": 100}
    },
    timeout=60
)

if response.status_code == 200:
    answer = response.json().get("response", "")
    print(f"   âœ… Respuesta recibida ({len(answer)} chars)")
    print(f"\nğŸ“ Respuesta:\n{answer[:300]}...")
else:
    print(f"   âŒ Error: {response.status_code}")

print("\n" + "="*50)
print("âœ… Ollama funcionando correctamente!")
