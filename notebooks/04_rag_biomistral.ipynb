{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG M\u00e9dico con BioMistral - Sistema de An\u00e1lisis Cl\u00ednico\n",
                "\n",
                "**Asignatura:** Transformers del Lenguaje en Salud (UPCH)\n",
                "\n",
                "## Objetivo\n",
                "\n",
                "Sistema RAG (Retrieval-Augmented Generation) que:\n",
                "- \u2705 Usa **BioMistral-7B** (LLM m\u00e9dico especializado)\n",
                "- \u2705 **PubMedBERT** para embeddings m\u00e9dicos\n",
                "- \u2705 Se integra con **NER + EntityLinker** existente\n",
                "- \u2705 B\u00fasqueda en knowledge base m\u00e9dica\n",
                "- \u2705 Soporta m\u00faltiples backends (HF API, HF Local, Ollama)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e3 Instalaci\u00f3n de Dependencias"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "\u2705 Dependencias instaladas\n"
                    ]
                }
            ],
            "source": [
                "# Instalaci\u00f3n de paquetes necesarios\n",
                "%pip install -q langchain langchain-community langchain-huggingface langchain-text-splitters\n",
                "%pip install -q faiss-cpu\n",
                "%pip install -q transformers accelerate\n",
                "%pip install -q sentence-transformers\n",
                "%pip install -q python-docx pypdf\n",
                "\n",
                "print(\"\u2705 Dependencias instaladas\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2\ufe0f\u20e3 Importaci\u00f3n de Librer\u00edas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2705 Librer\u00edas importadas correctamente\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "import os\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# Langchain\n",
                "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain_community.vectorstores import FAISS\n",
                "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
                "# \u2705 CORREGIDO: Usando LangChain Core LCEL\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from operator import itemgetter\n",
                "\n",
                "# Hugging Face\n",
                "from huggingface_hub import login\n",
                "\n",
                "print(\"\u2705 Librer\u00edas importadas correctamente\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3\ufe0f\u20e3 Configuraci\u00f3n de Hugging Face\n",
                "\n",
                "**IMPORTANTE:** Necesitas un token de Hugging Face (gratuito)\n",
                "- Ir a: https://huggingface.co/settings/tokens\n",
                "- Crear token con permisos de lectura\n",
                "- Pegar abajo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2705 Autenticado en Hugging Face\n"
                    ]
                }
            ],
            "source": [
                "# Configurar tu token de Hugging Face\n",
                "HF_TOKEN = \"\"  # \u2b05\ufe0f TOKEN ELIMINADO POR SEGURIDAD\n",
                "\n",
                "if HF_TOKEN:\n",
                "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN\n",
                "    login(token=HF_TOKEN)\n",
                "    print(\"\u2705 Autenticado en Hugging Face\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f Configura tu token de Hugging Face\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4\ufe0f\u20e3 Embeddings M\u00e9dicos: PubMedBERT\n",
                "\n",
                "Usamos PubMedBERT porque:\n",
                "- Entrenado en literatura m\u00e9dica (PubMed)\n",
                "- Comprende mejor terminolog\u00eda m\u00e9dica\n",
                "- Mejor retrieval para docs m\u00e9dicos vs embeddings gen\u00e9ricos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u23f3 Cargando PubMedBERT para embeddings...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "No sentence-transformers model found with name microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract. Creating a new one with mean pooling.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2705 PubMedBERT listo: dimensi\u00f3n = 768\n"
                    ]
                }
            ],
            "source": [
                "print(\"\u23f3 Cargando PubMedBERT para embeddings...\")\n",
                "\n",
                "embeddings = HuggingFaceEmbeddings(\n",
                "    model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
                "    model_kwargs={'device': 'cpu'},\n",
                "    encode_kwargs={'normalize_embeddings': True}\n",
                ")\n",
                "\n",
                "# Test\n",
                "test_embedding = embeddings.embed_query(\"diabetes mellitus treatment\")\n",
                "print(f\"\u2705 PubMedBERT listo: dimensi\u00f3n = {len(test_embedding)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5\ufe0f\u20e3 Preparar Knowledge Base M\u00e9dica\n",
                "\n",
                "Crea una carpeta `medical_knowledge/` y a\u00f1ade documentos m\u00e9dicos:\n",
                "- Gu\u00edas cl\u00ednicas (PDF, TXT)\n",
                "- Protocolos\n",
                "- Art\u00edculos de referencia"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2705 Documento de ejemplo creado\n",
                        "\u2705 Documento ICC creado\n",
                        "\ud83d\udcc1 Knowledge base en: /Users/smiljaandreasalazarcortez/PROYECTO_DIPLOMADO/Proyecto_T_L/notebooks/medical_knowledge\n"
                    ]
                }
            ],
            "source": [
                "# Crear directorio de ejemplo si no existe\n",
                "knowledge_dir = Path(\"medical_knowledge\")\n",
                "knowledge_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Documento de ejemplo sobre diabetes\n",
                "example_doc = knowledge_dir / \"diabetes_guideline.txt\"\n",
                "if not example_doc.exists():\n",
                "    example_doc.write_text(\"\"\"\n",
                "GU\u00cdA CL\u00cdNICA: DIABETES MELLITUS TIPO 2\n",
                "\n",
                "DIAGN\u00d3STICO:\n",
                "- Glucosa en ayunas \u2265126 mg/dL (7.0 mmol/L)\n",
                "- HbA1c \u22656.5%\n",
                "- Glucosa aleatoria \u2265200 mg/dL con s\u00edntomas\n",
                "\n",
                "COMPLICACIONES COMUNES:\n",
                "1. Cardiovasculares (IAM, ICC)\n",
                "   - DM2 aumenta 2-4x riesgo cardiovascular\n",
                "   - Asociaci\u00f3n frecuente con hipertensi\u00f3n arterial\n",
                "   \n",
                "2. Nefropat\u00eda diab\u00e9tica\n",
                "3. Retinopat\u00eda\n",
                "4. Neuropat\u00eda\n",
                "\n",
                "TRATAMIENTO FARMACOL\u00d3GICO:\n",
                "Primera l\u00ednea: Metformina 500-850mg\n",
                "- Contraindicaciones: ICC descompensada, insuficiencia renal\n",
                "- Efectos adversos: Intolerancia gastrointestinal, acidosis l\u00e1ctica (rara)\n",
                "\n",
                "HIPERTENSI\u00d3N EN DIAB\u00c9TICOS:\n",
                "Objetivo: PA <140/90 mmHg\n",
                "F\u00e1rmacos preferidos:\n",
                "- IECA (Enalapril, Lisinopril)\n",
                "- ARA-II (Losart\u00e1n, Valsart\u00e1n)\n",
                "  * Losart\u00e1n 50-100mg/d\u00eda\n",
                "  * Nefroprotector\n",
                "  * Bien tolerado en diab\u00e9ticos\n",
                "\n",
                "S\u00cdNTOMAS DE ALARMA:\n",
                "- Disnea s\u00fabita: considerar ICC (especialmente si DM2 + HTA)\n",
                "- Dolor tor\u00e1cico: IAM silente com\u00fan en diab\u00e9ticos\n",
                "- Edema en miembros inferiores: ICC o nefropat\u00eda\n",
                "\n",
                "REFERENCIA: Adaptado de ADA Standards of Medical Care in Diabetes 2024\n",
                "    \"\"\")\n",
                "    print(\"\u2705 Documento de ejemplo creado\")\n",
                "\n",
                "# Documento sobre ICC\n",
                "icc_doc = knowledge_dir / \"heart_failure.txt\"\n",
                "if not icc_doc.exists():\n",
                "    icc_doc.write_text(\"\"\"\n",
                "GU\u00cdA: INSUFICIENCIA CARD\u00cdACA CONGESTIVA (ICC)\n",
                "\n",
                "FACTORES DE RIESGO:\n",
                "- Hipertensi\u00f3n arterial (causa principal)\n",
                "- Diabetes Mellitus\n",
                "- Enfermedad coronaria\n",
                "- Edad avanzada (>65 a\u00f1os)\n",
                "\n",
                "PRESENTACI\u00d3N CL\u00cdNICA:\n",
                "S\u00edntomas:\n",
                "- Disnea de esfuerzo (s\u00edntoma cardinal)\n",
                "- Ortopnea\n",
                "- Disnea parox\u00edstica nocturna\n",
                "- Fatiga\n",
                "- Edema en MMII\n",
                "\n",
                "Signos:\n",
                "- Taquicardia\n",
                "- Crepitantes pulmonares\n",
                "- Ingurgitaci\u00f3n yugular\n",
                "- Hepatomegalia\n",
                "\n",
                "DIAGN\u00d3STICO:\n",
                "1. Ecocardiograma (Gold standard)\n",
                "   - Evaluar FE (fracci\u00f3n de eyecci\u00f3n)\n",
                "2. BNP/Pro-BNP\n",
                "   - BNP >100 pg/mL sugiere ICC\n",
                "3. Radiograf\u00eda t\u00f3rax\n",
                "   - Cardiomegalia, congesti\u00f3n pulmonar\n",
                "\n",
                "TRATAMIENTO:\n",
                "Medidas generales:\n",
                "- Restricci\u00f3n de sal (<2g/d\u00eda)\n",
                "- Control de l\u00edquidos\n",
                "- Ejercicio moderado (cuando est\u00e9 estable)\n",
                "\n",
                "Farmacol\u00f3gico:\n",
                "- Diur\u00e9ticos (furosemida)\n",
                "- IECA/ARA-II (continuar si ya los toma)\n",
                "- \u26a0\ufe0f METFORMINA: CONTRAINDICADA en ICC descompensada\n",
                "  * Riesgo de acidosis l\u00e1ctica\n",
                "  * Suspender temporalmente\n",
                "\n",
                "PACIENTE DIAB\u00c9TICO CON ICC:\n",
                "- Ajustar hipoglucemiantes (evitar metformina)\n",
                "- Control estricto de PA\n",
                "- Monitoreo frecuente\n",
                "\n",
                "REFERENCIA: ESC Guidelines for Heart Failure 2024\n",
                "    \"\"\")\n",
                "    print(\"\u2705 Documento ICC creado\")\n",
                "\n",
                "print(f\"\ud83d\udcc1 Knowledge base en: {knowledge_dir.absolute()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6\ufe0f\u20e3 Cargar y Procesar Documentos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\ud83d\udcda Cargando documentos m\u00e9dicos...\n",
                        "\u2705 Cargados 2 documentos\n",
                        "\u2705 Divididos en 6 chunks\n",
                        "\n",
                        "\ud83d\udcc4 Ejemplo de chunk:\n",
                        "GU\u00cdA CL\u00cdNICA: DIABETES MELLITUS TIPO 2\n",
                        "\n",
                        "DIAGN\u00d3STICO:\n",
                        "- Glucosa en ayunas \u2265126 mg/dL (7.0 mmol/L)\n",
                        "- HbA1c \u22656.5%\n",
                        "- Glucosa aleatoria \u2265200 mg/dL con s\u00edntomas\n",
                        "\n",
                        "COMPLICACIONES COMUNES:\n",
                        "1. Cardiovasculares ...\n"
                    ]
                }
            ],
            "source": [
                "print(\"\ud83d\udcda Cargando documentos m\u00e9dicos...\")\n",
                "\n",
                "# Cargar documentos\n",
                "loader = DirectoryLoader(\n",
                "    str(knowledge_dir),\n",
                "    glob=\"**/*.txt\",\n",
                "    loader_cls=TextLoader\n",
                ")\n",
                "documents = loader.load()\n",
                "\n",
                "print(f\"\u2705 Cargados {len(documents)} documentos\")\n",
                "\n",
                "# Split en chunks\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=500,  # Chunks m\u00e1s grandes para contexto m\u00e9dico\n",
                "    chunk_overlap=100,\n",
                "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
                ")\n",
                "chunks = text_splitter.split_documents(documents)\n",
                "\n",
                "print(f\"\u2705 Divididos en {len(chunks)} chunks\")\n",
                "print(f\"\\n\ud83d\udcc4 Ejemplo de chunk:\\n{chunks[0].page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7\ufe0f\u20e3 Crear Vector Database (FAISS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u23f3 Creando vector database...\n",
                        "\u2705 Vector database creada con 6 vectores\n",
                        "\n",
                        "\ud83d\udd0d Test b\u00fasqueda: 'tratamiento diabetes hipertensi\u00f3n'\n",
                        "Resultado 1: S\u00cdNTOMAS DE ALARMA:\n",
                        "- Disnea s\u00fabita: considerar ICC (especialmente si DM2 + HTA)\n",
                        "- Dolor tor\u00e1cico: IAM silente com\u00fan en diab\u00e9ticos\n",
                        "- Edema en miembros...\n"
                    ]
                }
            ],
            "source": [
                "print(\"\u23f3 Creando vector database...\")\n",
                "\n",
                "vector_db = FAISS.from_documents(\n",
                "    documents=chunks,\n",
                "    embedding=embeddings\n",
                ")\n",
                "\n",
                "print(f\"\u2705 Vector database creada con {len(chunks)} vectores\")\n",
                "\n",
                "# Test de b\u00fasqueda\n",
                "test_query = \"tratamiento diabetes hipertensi\u00f3n\"\n",
                "test_results = vector_db.similarity_search(test_query, k=2)\n",
                "\n",
                "print(f\"\\n\ud83d\udd0d Test b\u00fasqueda: '{test_query}'\")\n",
                "print(f\"Resultado 1: {test_results[0].page_content[:150]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8\ufe0f\u20e3 Configurar BioMistral (LLM M\u00e9dico)\n",
                "\n",
                "**BioMistral-7B:** Modelo Mistral fine-tuned en datos m\u00e9dicos\n",
                "- Estado del arte en benchmarks m\u00e9dicos\n",
                "- Multiling\u00fce (espa\u00f1ol m\u00e9dico incluido)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u23f3 Configurando BioMistral...\n"
                    ]
                },
                {
                    "ename": "StopIteration",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceEndpoint(\n\u001b[1;32m      4\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBioMistral/BioMistral-7B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     huggingfacehub_api_token\u001b[38;5;241m=\u001b[39mHF_TOKEN\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Test simple\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m test_response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is diabetes mellitus?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\u2705 BioMistral listo\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\ud83d\udcdd Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_response[:\u001b[38;5;241m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/language_models/llms.py:378\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    376\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    390\u001b[0m     )\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/language_models/llms.py:789\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    787\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    788\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1011\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    994\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    995\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         )\n\u001b[1;32m   1010\u001b[0m     ]\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1019\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1020\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[1;32m   1029\u001b[0m     ]\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/language_models/llms.py:815\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    806\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    812\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    814\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 815\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    823\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1505\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1502\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1504\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1505\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1509\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:341\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         completion \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n\u001b[0;32m--> 341\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stop_seq \u001b[38;5;129;01min\u001b[39;00m invocation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2356\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI endpoint/model for text-generation is not served via TGI. Cannot return output as a stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pass `stream=False` as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2353\u001b[0m         )\n\u001b[1;32m   2355\u001b[0m model_id \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m-> 2356\u001b[0m provider_helper \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2357\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m   2358\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   2359\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m   2364\u001b[0m )\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/huggingface_hub/inference/_providers/__init__.py:217\u001b[0m, in \u001b[0;36mget_provider_helper\u001b[0;34m(provider, task, model)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying a model is required when provider is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m     provider_mapping \u001b[38;5;241m=\u001b[39m _fetch_inference_provider_mapping(model)\n\u001b[0;32m--> 217\u001b[0m     provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprovider_mapping\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprovider\n\u001b[1;32m    219\u001b[0m provider_tasks \u001b[38;5;241m=\u001b[39m PROVIDERS\u001b[38;5;241m.\u001b[39mget(provider)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m provider_tasks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[0;31mStopIteration\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "print(\"\u23f3 Configurando BioMistral...\")\n",
                "\n",
                "llm = HuggingFaceEndpoint(\n",
                "    repo_id=\"BioMistral/BioMistral-7B\",\n",
                "    task=\"text-generation\",\n",
                "    max_new_tokens=512,\n",
                "    temperature=0.3,  # M\u00e1s bajo para respuestas m\u00e9dicas precisas\n",
                "    top_p=0.9,\n",
                "    repetition_penalty=1.1,\n",
                "    huggingfacehub_api_token=HF_TOKEN\n",
                ")\n",
                "\n",
                "# Test simple\n",
                "test_response = llm.invoke(\"What is diabetes mellitus?\")\n",
                "print(f\"\u2705 BioMistral listo\\n\\n\ud83d\udcdd Test: {test_response[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9\ufe0f\u20e3 Prompt Template M\u00e9dico"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prompt especializado para an\u00e1lisis cl\u00ednico\n",
                "medical_prompt_template = \"\"\"You are a specialized medical assistant. You will analyze clinical information and provide evidence-based insights.\n",
                "\n",
                "MEDICAL KNOWLEDGE (from guidelines):\n",
                "{context}\n",
                "\n",
                "CLINICAL QUESTION:\n",
                "{question}\n",
                "\n",
                "INSTRUCTIONS:\n",
                "1. Base your answer ONLY on the provided medical knowledge\n",
                "2. Provide differential diagnoses when relevant\n",
                "3. Include management recommendations from guidelines\n",
                "4. Highlight any contraindications or alerts\n",
                "5. Cite specific guideline references\n",
                "\n",
                "ANSWER:\n",
                "\"\"\"\n",
                "\n",
                "MEDICAL_PROMPT = PromptTemplate(\n",
                "    template=medical_prompt_template,\n",
                "    input_variables=[\"context\", \"question\"]\n",
                ")\n",
                "\n",
                "print(\"\u2705 Prompt template configurado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83d\udd1f Pipeline RAG Completo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\u23f3 Construyendo pipeline RAG...\")\n",
                "\n",
                "# Crear retriever\n",
                "retriever = vector_db.as_retriever(\n",
                "    search_type=\"similarity\",\n",
                "    search_kwargs={\"k\": 3}  # Top 3 documentos m\u00e1s relevantes\n",
                ")\n",
                "\n",
                "# Crear chain RAG\n",
                "rag_chain = RetrievalQA.from_chain_type(\n",
                "    llm=llm,\n",
                "    chain_type=\"stuff\",\n",
                "    retriever=retriever,\n",
                "    chain_type_kwargs={\"prompt\": MEDICAL_PROMPT},\n",
                "    return_source_documents=True\n",
                ")\n",
                "\n",
                "print(\"\u2705 Pipeline RAG listo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e31\ufe0f\u20e3 Funci\u00f3n Helper para Consultas M\u00e9dicas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def medical_query(question, verbose=True):\n",
                "    \"\"\"\n",
                "    Realiza una consulta m\u00e9dica al sistema RAG.\n",
                "    \n",
                "    Args:\n",
                "        question: Pregunta cl\u00ednica\n",
                "        verbose: Mostrar documentos recuperados\n",
                "    \n",
                "    Returns:\n",
                "        Respuesta del LLM con referencias\n",
                "    \"\"\"\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"\ud83e\ude7a CONSULTA M\u00c9DICA\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"\\n\u2753 Pregunta: {question}\\n\")\n",
                "    \n",
                "    # Ejecutar RAG\n",
                "    result = rag_chain.invoke({\"query\": question})\n",
                "    \n",
                "    # Mostrar documentos recuperados\n",
                "    if verbose and 'source_documents' in result:\n",
                "        print(\"\ud83d\udcda Conocimiento m\u00e9dico recuperado:\")\n",
                "        for i, doc in enumerate(result['source_documents'], 1):\n",
                "            print(f\"\\n[{i}] Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
                "            print(f\"Contenido: {doc.page_content[:200]}...\\n\")\n",
                "    \n",
                "    print(\"=\"*60)\n",
                "    print(\"\ud83d\udc8a RESPUESTA\")\n",
                "    print(\"=\"*60)\n",
                "    print(result['result'])\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    \n",
                "    return result\n",
                "\n",
                "print(\"\u2705 Funci\u00f3n helper definida\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e32\ufe0f\u20e3 EJEMPLO 1: Consulta B\u00e1sica"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pregunta simple sobre diabetes\n",
                "question1 = \"What is the first-line treatment for type 2 diabetes?\"\n",
                "\n",
                "result1 = medical_query(question1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e33\ufe0f\u20e3 EJEMPLO 2: Caso Cl\u00ednico Complejo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Caso cl\u00ednico: Paciente diab\u00e9tico con disnea\n",
                "clinical_case = \"\"\"\n",
                "A 65-year-old male patient with type 2 diabetes mellitus and hypertension \n",
                "presents with 3 days of dyspnea on exertion. \n",
                "Current medications: Losartan 50mg daily, Metformin 850mg daily.\n",
                "What are the differential diagnoses and management considerations?\n",
                "\"\"\"\n",
                "\n",
                "result2 = medical_query(clinical_case)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e34\ufe0f\u20e3 Integraci\u00f3n con NER (Opcional)\n",
                "\n",
                "Si tienes el NER ejecutado del notebook anterior:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def enrich_query_with_ner(clinical_text, ner_results):\n",
                "    \"\"\"\n",
                "    Enriquece una query con informaci\u00f3n del NER.\n",
                "    \n",
                "    Args:\n",
                "        clinical_text: Texto cl\u00ednico original\n",
                "        ner_results: JSON output del notebook NER\n",
                "    \n",
                "    Returns:\n",
                "        Query enriquecido con UMLS IDs y terminolog\u00eda normalizada\n",
                "    \"\"\"\n",
                "    enriched_query = f\"Clinical case: {clinical_text}\\n\\n\"\n",
                "    \n",
                "    # A\u00f1adir enfermedades detectadas\n",
                "    if 'ENFERMEDAD' in ner_results.get('entidades_por_categoria', {}):\n",
                "        enriched_query += \"Diagnosed conditions:\\n\"\n",
                "        for disease in ner_results['entidades_por_categoria']['ENFERMEDAD']:\n",
                "            nombre = disease.get('nombre_normalizado', disease.get('texto_original'))\n",
                "            umls = disease.get('umls_id', '')\n",
                "            enriched_query += f\"- {nombre} (UMLS: {umls})\\n\"\n",
                "    \n",
                "    # A\u00f1adir medicamentos\n",
                "    if 'MEDICAMENTO' in ner_results.get('entidades_por_categoria', {}):\n",
                "        enriched_query += \"\\nCurrent medications:\\n\"\n",
                "        for med in ner_results['entidades_por_categoria']['MEDICAMENTO']:\n",
                "            nombre = med.get('nombre_normalizado', med.get('texto_original'))\n",
                "            enriched_query += f\"- {nombre}\\n\"\n",
                "    \n",
                "    # A\u00f1adir s\u00edntomas\n",
                "    if 'SINTOMA' in ner_results.get('entidades_por_categoria', {}):\n",
                "        enriched_query += \"\\nPresenting symptoms:\\n\"\n",
                "        for symptom in ner_results['entidades_por_categoria']['SINTOMA']:\n",
                "            nombre = symptom.get('nombre_normalizado', symptom.get('texto_original'))\n",
                "            contexto = symptom.get('contexto', {})\n",
                "            temp = contexto.get('temporalidad', '')\n",
                "            enriched_query += f\"- {nombre} ({temp})\\n\"\n",
                "    \n",
                "    return enriched_query\n",
                "\n",
                "print(\"\u2705 Funci\u00f3n de integraci\u00f3n NER definida\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e35\ufe0f\u20e3 Ejemplo con NER Integration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulaci\u00f3n de output NER (reemplazar con tu NER real)\n",
                "ner_example = {\n",
                "    \"entidades_por_categoria\": {\n",
                "        \"ENFERMEDAD\": [\n",
                "            {\n",
                "                \"texto_original\": \"Diabetes Mellitus tipo 2\",\n",
                "                \"umls_id\": \"C0011860\",\n",
                "                \"nombre_normalizado\": \"Diabetes Mellitus, Type 2\"\n",
                "            },\n",
                "            {\n",
                "                \"texto_original\": \"Hipertensi\u00f3n arterial\",\n",
                "                \"umls_id\": \"C0020538\",\n",
                "                \"nombre_normalizado\": \"Hypertension\"\n",
                "            }\n",
                "        ],\n",
                "        \"MEDICAMENTO\": [\n",
                "            {\n",
                "                \"texto_original\": \"Losart\u00e1n\",\n",
                "                \"nombre_normalizado\": \"Losartan\"\n",
                "            },\n",
                "            {\n",
                "                \"texto_original\": \"Metformina\",\n",
                "                \"nombre_normalizado\": \"Metformin\"\n",
                "            }\n",
                "        ],\n",
                "        \"SINTOMA\": [\n",
                "            {\n",
                "                \"texto_original\": \"disnea\",\n",
                "                \"nombre_normalizado\": \"Dyspnea\",\n",
                "                \"contexto\": {\"temporalidad\": \"actual\"}\n",
                "            }\n",
                "        ]\n",
                "    }\n",
                "}\n",
                "\n",
                "# Historia cl\u00ednica original\n",
                "clinical_text = \"Paciente de 65 a\u00f1os con disnea de 3 d\u00edas\"\n",
                "\n",
                "# Enriquecer query\n",
                "enriched_query = enrich_query_with_ner(clinical_text, ner_example)\n",
                "\n",
                "print(\"\ud83d\udcdd Query enriquecido con NER:\\n\")\n",
                "print(enriched_query)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "\n",
                "# Consultar RAG con query enriquecido\n",
                "result_ner = medical_query(f\"{enriched_query}\\n\\nWhat is the most likely diagnosis and recommended management?\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1\ufe0f\u20e36\ufe0f\u20e3 Guardar Vector Database (Para Reutilizar)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Guardar vector DB\n",
                "db_path = \"medical_vector_db\"\n",
                "vector_db.save_local(db_path)\n",
                "print(f\"\u2705 Vector database guardada en: {db_path}\")\n",
                "\n",
                "# Para cargar despu\u00e9s:\n",
                "# vector_db_loaded = FAISS.load_local(db_path, embeddings)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83c\udfaf Pr\u00f3ximos Pasos\n",
                "\n",
                "### Mejoras Sugeridas:\n",
                "\n",
                "1. **M\u00e1s documentos m\u00e9dicos:**\n",
                "   - A\u00f1adir m\u00e1s gu\u00edas cl\u00ednicas a `medical_knowledge/`\n",
                "   - Protocolos locales de tu instituci\u00f3n\n",
                "\n",
                "2. **Filtrado por metadata:**\n",
                "   - Especialidad m\u00e9dica\n",
                "   - UMLS IDs espec\u00edficos\n",
                "   - A\u00f1o de publicaci\u00f3n\n",
                "\n",
                "3. **Backend alternativo (Ollama):**\n",
                "   - Instalar: `ollama pull meditron:7b`\n",
                "   - Usar para privacidad total (local)\n",
                "\n",
                "4. **Fine-tuning:**\n",
                "   - Ajustar BioMistral con casos cl\u00ednicos locales\n",
                "   - Mejorar respuestas espec\u00edficas a tu contexto\n",
                "\n",
                "5. **UI con Streamlit:**\n",
                "   - Interfaz web para uso interactivo\n",
                "   - Integraci\u00f3n completa NER + RAG\n",
                "\n",
                "---\n",
                "\n",
                "## \ud83d\udcda Referencias\n",
                "\n",
                "- **BioMistral:** https://huggingface.co/BioMistral/BioMistral-7B\n",
                "- **PubMedBERT:** https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n",
                "- **Langchain:** https://python.langchain.com/\n",
                "- **NER Notebook:** `3_ner_avanzado_entitylinker.ipynb`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}